{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import sys\n",
    "import shutil\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import optimizers, losses, callbacks, regularizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Lambda, Concatenate, Dropout\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler, Callback\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_list = ['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr','Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu']\n",
    "df_train = pd.read_csv('../Data/oqmd_train.csv')\n",
    "df_test = pd.read_csv('../Data/oqmd_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert string representation of molecular formula to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts2vector(pairs):\n",
    "    vec = [0]*len(element_list)\n",
    "    for pair in pairs:\n",
    "        vec[element_list.index(pair[0])]+=int(pair[1])\n",
    "    vec = np.array(vec)\n",
    "    return vec\n",
    "\n",
    "def onehot(enc):\n",
    "    rep = np.zeros((len(element_list),11))\n",
    "    rep[:,0] = 1\n",
    "    for i,val in enumerate(enc):\n",
    "        if val!=0:\n",
    "            rep[i][0]=0\n",
    "            rep[i][val]=1\n",
    "    return rep.flatten()\n",
    "\n",
    "def encode(df):\n",
    "    formulae = df[['comp']]\n",
    "    counts = pd.Series(formulae.values.flatten()).str.findall(r\"([a-z]+)([0-9]+)\", re.I)\n",
    "    df['encoding'] = counts.apply(counts2vector)\n",
    "    df['onehot'] = df['encoding'].apply(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode(df_train)\n",
    "encode(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the encoding and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.onehot.values\n",
    "X_train = np.stack(X_train,axis=0)\n",
    "X_test = df_test.onehot.values\n",
    "X_test = np.stack(X_test,axis=0)\n",
    "y_train = df_train[['delta_e','volume_pa','energy_pa']].values\n",
    "y_test = df_test[['delta_e','volume_pa','energy_pa']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator model - VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_z = 32  # dimension of latent space\n",
    "n_x = X_train.shape[1] \n",
    "\n",
    "inputs = Input(shape=(n_x,))\n",
    "h_q = Dense(512, activation='relu')(inputs)\n",
    "h_q1= Dense(256, activation='relu')(h_q)\n",
    "h_q2= Dense(128, activation='relu')(h_q1)\n",
    "mu = Dense(n_z, activation='linear')(h_q2)\n",
    "log_sigma = Dense(n_z, activation='linear')(h_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to sample points in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(args):\n",
    "    mu, log_sigma = args\n",
    "    eps = K.random_normal(shape=(n_z,), mean=0., stddev=1.)\n",
    "    return mu + K.exp(log_sigma / 2.) * eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true, y_pred):\n",
    "    \n",
    "    # Reconstruction Loss\n",
    "    y_true_reshaped=tf.reshape(y_true,[-1,89,11])\n",
    "    recon = 10 * K.mean(K.sum(K.categorical_crossentropy(y_true_reshaped, y_pred, axis=2),axis=1))\n",
    "\n",
    "    # KL Divergence Loss\n",
    "    kl = 0.05 * K.sum(K.exp(log_sigma) + K.square(mu) - 1. - log_sigma, axis=1)\n",
    "    \n",
    "    #Total loss\n",
    "    return recon + kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Lambda(sample_z)([mu, log_sigma])\n",
    "\n",
    "decoder_hidden = Dense(128, activation='relu')\n",
    "decoder_hidden_1 = Dense(256, activation='relu')\n",
    "decoder_hidden_2 = Dense(512, activation='relu')\n",
    "decoder_out = Dense(n_x, activation='linear')\n",
    "decoder_out_act = Lambda(lambda x: K.softmax(K.reshape(x,(-1,89,11)), axis=2))\n",
    "\n",
    "h_p = decoder_hidden(z)\n",
    "h_p1=decoder_hidden_1(h_p)\n",
    "h_p2=decoder_hidden_2(h_p1)\n",
    "\n",
    "outputs = decoder_out_act(decoder_out(h_p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall VAE for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = Model(inputs, outputs)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder and Encoder Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the mean as the output as it is the center point, the representative of the gaussian\n",
    "encoder = Model(inputs, mu)\n",
    "\n",
    "# Generator model, generate new data given latent variable z \n",
    "d_inputs = Input(shape=(n_z,))\n",
    "d_h = decoder_hidden(d_inputs)\n",
    "d_h1 = decoder_hidden_1(d_h)\n",
    "d_h2 = decoder_hidden_2(d_h1)\n",
    "d_out = decoder_out_act(decoder_out(d_h2))\n",
    "decoder = Model(d_inputs, d_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=0.00000001,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderSaveCheckpoint(Callback):\n",
    "    def __init__(self, filepath, decoder):\n",
    "        self.monitor = 'val_loss'\n",
    "        self.monitor_op = np.less\n",
    "        self.best = np.Inf\n",
    "\n",
    "        self.filepath = filepath\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if self.monitor_op(current, self.best):\n",
    "            self.best = current\n",
    "            self.decoder.save(self.filepath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=[]\n",
    "checkpoint=callbacks.ModelCheckpoint(filepath='vae_model_best.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "save_loss = callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: [\n",
    "        losses.append(logs['val_loss'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(X_train, X_train, batch_size=256, epochs=150, validation_split=0.2,callbacks=[reduce_lr,checkpoint,save_loss, DecoderSaveCheckpoint('vae_decoder_best.h5', decoder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(vae.history.history['loss'])\n",
    "plt.plot(vae.history.history['val_loss'])\n",
    "plt.title(\"Performance of DING model with increase in epochs \")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train','Validation'],loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find reconstruction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = vae.predict(X_test)\n",
    "Y_pred = Y_pred.reshape(-1,89,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_encoding = np.zeros((Y_pred.shape[0],89))\n",
    "Y_pred[Y_pred<0.5]=0\n",
    "\n",
    "for i,mol in enumerate(Y_pred):\n",
    "    for j,atom in enumerate(mol):\n",
    "        if atom.max()!=0:\n",
    "            pred_encoding[i][j] = atom.argmax()\n",
    "\n",
    "test_encoding = np.zeros_like(pred_encoding)\n",
    "for i,mol in enumerate(X_test.reshape(-1,89,11)):\n",
    "    for j,atom in enumerate(mol):\n",
    "        if atom.max()!=0:\n",
    "            test_encoding[i][j] = atom.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (np.unique(np.sum(np.abs(pred_encoding - test_encoding),axis=1),return_counts=True))[1]*100/len(X_test)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
